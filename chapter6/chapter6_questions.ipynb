{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using the hash table performance formulas given in the chapter, compute the average number of comparisons necessary when the table is\n",
    "\n",
    "* ### 10% full\n",
    "\n",
    "* ### 25% full\n",
    "\n",
    "* ### 50% full\n",
    "\n",
    "* ### 75% full\n",
    "\n",
    "* ### 90% full\n",
    "\n",
    "* ### 99% full\n",
    "\n",
    "### At what point do you think the hash table is too small? Explain.\n",
    "\n",
    "Let's define first some helper functions to get us the given formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_search(lf):\n",
    "    return (1 / 2) * (1 + 1 / (1 - lf))\n",
    "\n",
    "def unsuccessful_search(lf):\n",
    "    return (1 / 2) * (1 + ((1 / (1 - lf)) ** 2))\n",
    "\n",
    "def successful_search_chaining(lf):\n",
    "    return 1 + (1 / lf)\n",
    "\n",
    "def unsuccessful_search_chaining(lf):\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the average number of searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful (no chaining) for load factor 0.1: 1.0555555555555556\n",
      "Successful (no chaining) for load factor 0.25: 1.1666666666666665\n",
      "Successful (no chaining) for load factor 0.5: 1.5\n",
      "Successful (no chaining) for load factor 0.75: 2.5\n",
      "Successful (no chaining) for load factor 0.9: 5.500000000000001\n",
      "Successful (no chaining) for load factor 0.99: 50.49999999999996\n",
      "\n",
      "\n",
      "Unuccessful (no chaining) for load factor 0.1: 1.117283950617284\n",
      "Unuccessful (no chaining) for load factor 0.25: 1.3888888888888888\n",
      "Unuccessful (no chaining) for load factor 0.5: 2.5\n",
      "Unuccessful (no chaining) for load factor 0.75: 8.5\n",
      "Unuccessful (no chaining) for load factor 0.9: 50.50000000000002\n",
      "Unuccessful (no chaining) for load factor 0.99: 5000.499999999992\n",
      "\n",
      "\n",
      "Successful (with chaining) for load factor 0.1: 11.0\n",
      "Successful (with chaining) for load factor 0.25: 5.0\n",
      "Successful (with chaining) for load factor 0.5: 3.0\n",
      "Successful (with chaining) for load factor 0.75: 2.333333333333333\n",
      "Successful (with chaining) for load factor 0.9: 2.111111111111111\n",
      "Successful (with chaining) for load factor 0.99: 2.0101010101010104\n",
      "\n",
      "\n",
      "Unsuccessful (with chaining) for load factor 0.1: 0.1\n",
      "Unsuccessful (with chaining) for load factor 0.25: 0.25\n",
      "Unsuccessful (with chaining) for load factor 0.5: 0.5\n",
      "Unsuccessful (with chaining) for load factor 0.75: 0.75\n",
      "Unsuccessful (with chaining) for load factor 0.9: 0.9\n",
      "Unsuccessful (with chaining) for load factor 0.99: 0.99\n"
     ]
    }
   ],
   "source": [
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Successful (no chaining) for load factor {lf}: {successful_search(lf)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:    \n",
    "    print(f\"Unuccessful (no chaining) for load factor {lf}: {unsuccessful_search(lf)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Successful (with chaining) for load factor {lf}: {successful_search_chaining(lf)}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Unsuccessful (with chaining) for load factor {lf}: {unsuccessful_search_chaining(lf)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that after a load factor of 0.5 (it means that the hash table is half full), performances degrade (when not using chaining). We note that when the load factor is 0.99, the number of searches is very huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modify the hash function for strings to use positional weightings.\n",
    "\n",
    "We just need to multiply each character's ordinal value for its position within the string, and still perform the modulo operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str(a_string, table_size):\n",
    "    return sum([ord(c) for c in a_string]) % table_size\n",
    "\n",
    "def hash_str_pos_w(a_string, table_size):\n",
    "    return sum([ord(c) * i for i, c in enumerate(a_string)]) % table_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We used a hash function for strings that weighted the characters by position. Devise an alternative weighting scheme. What are the biases that exist with these functions?\n",
    "\n",
    "We might weight each character by its position inside the alphabet (so the weight would be `w = ord(ch) - ord(\"a\")`), but this approach would hash anagrams to the same position. An improvement of the positional weighting is to start with `i = 1` and not `i = 0`: in this latter case, strings such as `\"what\"` and `\"that\"` will collide, since the contribution of the first character is cancelled by the weight `i = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str_pos_w_better(a_string, table_size):\n",
    "    return sum([ord(c) * (i + 1) for i, c in enumerate(a_string)]) % table_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But still, even though both the letters and their position matter, we can still find combinations of words which will collide. With all these approach, another common problem might be due to a reduced hash table size, so choosing the appropriate size would be beneficial to avoid collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Research perfect hash functions. Using a list of names (classmates, family members, etc.), generate the hash values using the perfect hash algorithm.\n",
    "\n",
    "A perfect hash function is a hash function that maps distinct elements from a set to another set of `m` distinct integers, therefore making no collisions. In Python, [Perfect Hash](https://github.com/ilanschnell/perfect-hash) is an example of a perfect hash function generator which generates a perfect hash function, for a given set of words, such that each word maps to a distinct integer. You can install it with pip and try the algorithms by yourself. \n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "The code I linked above is not mine, so all the credits go to the original creator, i.e. the repository owner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate a random list of integers. Show how this list is sorted by the following algorithms:\n",
    "\n",
    "* ### bubble sort\n",
    "\n",
    "* ### selection sort\n",
    "\n",
    "* ### insertion sort\n",
    "\n",
    "* ### shell sort (you decide on the increments)\n",
    "\n",
    "* ### merge sort\n",
    "\n",
    "* ### quick sort (you decide on the pivot value)\n",
    "\n",
    "First let's write the different sorting algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bubble_sort(a, debug=False):\n",
    "    if debug:\n",
    "        print(a)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        for j in range(i, len(a)):\n",
    "            if debug:\n",
    "                print(a)\n",
    "            if a[i] > a[j]:\n",
    "                a[i], a[j] = a[j], a[i]\n",
    "\n",
    "def selection_sort(a, debug=False):\n",
    "    if debug:\n",
    "        print(a)\n",
    "    \n",
    "    for i, _ in enumerate(a):\n",
    "        min_idx = i\n",
    "        for j in range(i, len(a)):\n",
    "            if debug:\n",
    "                print(a)\n",
    "            if a[j] < a[min_idx]:\n",
    "                min_idx = j \n",
    "        if min_idx != i:\n",
    "            a[min_idx], a[i] = a[i], a[min_idx]\n",
    "\n",
    "def insertion_sort(a, debug):\n",
    "    if debug:\n",
    "        print(a)\n",
    "\n",
    "    for i in range(1, len(a)):\n",
    "        j = i\n",
    "        while j > 0 and a[j] < a[j - 1]:\n",
    "            if debug:\n",
    "                print(a)\n",
    "            a[j], a[j - 1] = a[j - 1], a[j]\n",
    "            j -= 1\n",
    "\n",
    "def shell_sort(a, increment=None, debug=False):\n",
    "    if debug:\n",
    "        print(a)\n",
    "    \n",
    "    increment = max(0, increment) if increment is not None else len(a) // 2\n",
    "    for gap in range(increment, 0, -1):\n",
    "        for i in range(gap, len(a), gap):\n",
    "            if debug:\n",
    "                print(a)\n",
    "            j = i\n",
    "            while j > 0 and a[j] < a[j - gap]:\n",
    "                a[j], a[j - gap] = a[j - gap], a[j]\n",
    "                j -= gap\n",
    "\n",
    "def merge_sort(a, debug=False):\n",
    "    if len(a) == 1:\n",
    "        return a\n",
    "    else:\n",
    "        mid = len(a) // 2\n",
    "        return merge(merge_sort(a[:mid], debug), merge_sort(a[mid:], debug), debug)\n",
    "\n",
    "def merge(a1, a2, debug=False):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    new_a = []\n",
    "\n",
    "    while p1 < len(a1) and p2 < len(a2):\n",
    "        if a1[p1] <= a2[p2]:\n",
    "            new_a += [a1[p1]]\n",
    "            p1 += 1\n",
    "        else:\n",
    "            new_a += [a2[p2]]\n",
    "            p2 += 1\n",
    "\n",
    "    while p1 < len(a1):\n",
    "        new_a += [a1[p1]]\n",
    "        p1 += 1\n",
    "\n",
    "    while p2 < len(a2):\n",
    "        new_a += [a2[p2]]\n",
    "        p2 += 1\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Merging {a1} and {a2} into {new_a}\")\n",
    "\n",
    "    return new_a\n",
    "\n",
    "def quick_sort(a, low=None, high=None, pivot=None, debug=False):\n",
    "    if low is None:\n",
    "        low = 0 \n",
    "    if high is None:\n",
    "        high = len(a) - 1\n",
    "\n",
    "    if low < high:\n",
    "        separator = partition(a, low, high, pivot, debug)\n",
    "        quick_sort(a, low, separator - 1, pivot, debug) \n",
    "        quick_sort(a, separator + 1, high, pivot, debug)\n",
    "\n",
    "def partition(a, low, high, pivot=None, debug=False):\n",
    "    if pivot == \"middle\":\n",
    "        pivot = (high + low) // 2\n",
    "    else:\n",
    "        pivot = random.randint(low, high)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Partitioning {a[low:high + 1]}\")\n",
    "        print(f\"Pivoting on {a[pivot]}\")\n",
    "        \n",
    "    la = [n for n in a[low:high + 1] if n < a[pivot]]\n",
    "    ma = [n for n in a[low:high + 1] if n == a[pivot]]\n",
    "    ha = [n for n in a[low:high + 1] if n > a[pivot]]\n",
    "\n",
    "    new_a = la + ma + ha\n",
    "    a[low:high + 1] = new_a[:]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"After pivot: {a}\")\n",
    "        print(f\"New split point is {low + len(la)}\")\n",
    "    \n",
    "    return low + len(la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how sorting a list with each of these algorithms works out. Let's first generate a random array of ten elements whose values range from 0 and 99. Then we can run the algorithms, in order, and see each step (by putting the argument `debug = True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random.sample(range(0, 100), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can either run the algorithms here (but the output will be collapsed) or we can run the scripts from the command line (we created a file containing the algorithms [here](./sorting_algorithms.py)) and pipe the output to the file [steps_q5.txt](./steps_q5.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python sorting_algorithms.py >> steps_q5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Consider the following list of integers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Show how this list is sorted by the following algorithms:\n",
    "\n",
    "* ### bubble sort\n",
    "\n",
    "* ### selection sort\n",
    "\n",
    "* ### insertion sort\n",
    "\n",
    "* ### shell sort (you decide on the increments)\n",
    "\n",
    "* ### merge sort\n",
    "\n",
    "* ### quick sort (you decide on the pivot value)\n",
    "\n",
    "Let's reuse the previous strategy, by saving the output in the file [steps_q6.txt](./steps_q6.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python sorting_algorithms.py >> steps_q6.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list is already sorted and the different algorithms might take more or less steps to \"figure it out\", but we can see how Insertion Sort is the quickest to figure that out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Consider the following list of integers: [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]. Show how this list is sorted by the following algorithms:\n",
    "\n",
    "* ### bubble sort\n",
    "\n",
    "* ### selection sort\n",
    "\n",
    "* ### insertion sort\n",
    "\n",
    "* ### shell sort (you decide on the increments)\n",
    "\n",
    "* ### merge sort\n",
    "\n",
    "* ### quick sort (you decide on the pivot value)\n",
    "\n",
    "Let's again reuse the previous strategy, by saving the output in the file [steps_q7.txt](./steps_q7.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python sorting_algorithms.py >> steps_q7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to notice how, given an input size, Merge Sort performs always the same number of steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Consider the list of characters: [\"P\", \"Y\", \"T\", \"H\", \"O\", \"N\"]. Show how this list is sorted using the following algorithms:\n",
    "\n",
    "* ### bubble sort\n",
    "\n",
    "* ### selection sort\n",
    "\n",
    "* ### insertion sort\n",
    "\n",
    "* ### shell sort (you decide on the increments)\n",
    "\n",
    "* ### merge sort\n",
    "\n",
    "* ### quick sort (you decide on the pivot value)\n",
    "\n",
    "Let's run the algorithms, and save the output in [steps_q8.txt](./steps_q8.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python sorting_algorithms.py >> steps_q8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Devise alternative strategies for choosing the pivot value in quick sort. For example, pick the middle item. Re-implement the algorithm and then execute it on random data sets. Under what criteria does your new strategy perform better or worse than the strategy from this chapter?\n",
    "\n",
    "We can call the `quick_sort` by explicitly passing a value for the pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python sorting_algorithms.py >> steps_q9.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only improvement one can get is if the list is already some sorted: in this case picking the first element as a pivot would be very inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc1c445b68446493975f0f4c1120652b32b7ff2d59b9297499b6aaef4c1ff08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
