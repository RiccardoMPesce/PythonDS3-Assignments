{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using the hash table performance formulas given in the chapter, compute the average number of comparisons necessary when the table is\n",
    "\n",
    "* ### 10% full\n",
    "\n",
    "* ### 25% full\n",
    "\n",
    "* ### 50% full\n",
    "\n",
    "* ### 75% full\n",
    "\n",
    "* ### 90% full\n",
    "\n",
    "* ### 99% full\n",
    "\n",
    "### At what point do you think the hash table is too small? Explain.\n",
    "\n",
    "Let's define first some helper functions to get us the given formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_search(lf):\n",
    "    return (1 / 2) * (1 + 1 / (1 - lf))\n",
    "\n",
    "def unsuccessful_search(lf):\n",
    "    return (1 / 2) * (1 + ((1 / (1 - lf)) ** 2))\n",
    "\n",
    "def successful_search_chaining(lf):\n",
    "    return 1 + (1 / lf)\n",
    "\n",
    "def unsuccessful_search_chaining(lf):\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the average number of searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful (no chaining) for load factor 0.1: 1.0555555555555556\n",
      "Successful (no chaining) for load factor 0.25: 1.1666666666666665\n",
      "Successful (no chaining) for load factor 0.5: 1.5\n",
      "Successful (no chaining) for load factor 0.75: 2.5\n",
      "Successful (no chaining) for load factor 0.9: 5.500000000000001\n",
      "Successful (no chaining) for load factor 0.99: 50.49999999999996\n",
      "\n",
      "\n",
      "Unuccessful (no chaining) for load factor 0.1: 1.117283950617284\n",
      "Unuccessful (no chaining) for load factor 0.25: 1.3888888888888888\n",
      "Unuccessful (no chaining) for load factor 0.5: 2.5\n",
      "Unuccessful (no chaining) for load factor 0.75: 8.5\n",
      "Unuccessful (no chaining) for load factor 0.9: 50.50000000000002\n",
      "Unuccessful (no chaining) for load factor 0.99: 5000.499999999992\n",
      "\n",
      "\n",
      "Successful (with chaining) for load factor 0.1: 11.0\n",
      "Successful (with chaining) for load factor 0.25: 5.0\n",
      "Successful (with chaining) for load factor 0.5: 3.0\n",
      "Successful (with chaining) for load factor 0.75: 2.333333333333333\n",
      "Successful (with chaining) for load factor 0.9: 2.111111111111111\n",
      "Successful (with chaining) for load factor 0.99: 2.0101010101010104\n",
      "\n",
      "\n",
      "Unsuccessful (with chaining) for load factor 0.1: 0.1\n",
      "Unsuccessful (with chaining) for load factor 0.25: 0.25\n",
      "Unsuccessful (with chaining) for load factor 0.5: 0.5\n",
      "Unsuccessful (with chaining) for load factor 0.75: 0.75\n",
      "Unsuccessful (with chaining) for load factor 0.9: 0.9\n",
      "Unsuccessful (with chaining) for load factor 0.99: 0.99\n"
     ]
    }
   ],
   "source": [
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Successful (no chaining) for load factor {lf}: {successful_search(lf)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:    \n",
    "    print(f\"Unuccessful (no chaining) for load factor {lf}: {unsuccessful_search(lf)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Successful (with chaining) for load factor {lf}: {successful_search_chaining(lf)}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for lf in [0.10, 0.25, 0.50, 0.75, 0.90, 0.99]:\n",
    "    print(f\"Unsuccessful (with chaining) for load factor {lf}: {unsuccessful_search_chaining(lf)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that after a load factor of 0.5 (it means that the hash table is half full), performances degrade (when not using chaining). We note that when the load factor is 0.99, the number of searches is very huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modify the hash function for strings to use positional weightings.\n",
    "\n",
    "We just need to multiply each character's ordinal value for its position within the string, and still perform the modulo operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str(a_string, table_size):\n",
    "    return sum([ord(c) for c in a_string]) % table_size\n",
    "\n",
    "def hash_str_pos_w(a_string, table_size):\n",
    "    return sum([ord(c) * i for i, c in enumerate(a_string)]) % table_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We used a hash function for strings that weighted the characters by position. Devise an alternative weighting scheme. What are the biases that exist with these functions?\n",
    "\n",
    "We might weight each character by its position inside the alphabet (so the weight would be `w = ord(ch) - ord(\"a\")`), but this approach would hash anagrams to the same position. An improvement of the positional weighting is to start with `i = 1` and not `i = 0`: in this latter case, strings such as `\"what\"` and `\"that\"` will collide, since the contribution of the first character is cancelled by the weight `i = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str_pos_w_better(a_string, table_size):\n",
    "    return sum([ord(c) * (i + 1) for i, c in enumerate(a_string)]) % table_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But still, even though both the letters and their position matter, we can still find combinations of words which will collide. With all these approach, another common problem might be due to a reduced hash table size, so choosing the appropriate size would be beneficial to avoid collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Research perfect hash functions. Using a list of names (classmates, family members, etc.), generate the hash values using the perfect hash algorithm.\n",
    "\n",
    "A perfect hash function is a hash function that maps distinct elements from a set to another set of `m` distinct integers, therefore making no collisions. In Python, [Perfect Hash](https://github.com/ilanschnell/perfect-hash) is an example of a perfect hash function generator which generates a perfect hash function, for a given set of words, such that each word maps to a distinct integer. You can install it with pip and try the algorithms by yourself. \n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "The code I linked above is not mine, so all the credits go to the original creator, i.e. the repository owner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate a random list of integers. Show how this list is sorted by the following algorithms:\n",
    "\n",
    "* ### bubble sort\n",
    "\n",
    "* ### selection sort\n",
    "\n",
    "* ### insertion sort\n",
    "\n",
    "* ### shell sort (you decide on the increments)\n",
    "\n",
    "* ### merge sort\n",
    "\n",
    "* ### quick sort (you decide on the pivot value)\n",
    "\n",
    "First let's write the different sorting algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bubble_sort(a):\n",
    "    for i in range(len(a)):\n",
    "        for j in range(i, len(a)):\n",
    "            if a[i] > a[j]:\n",
    "                a[i], a[j] = a[j], a[i]\n",
    "\n",
    "def selection_sort(a):\n",
    "    for i, _ in enumerate(a):\n",
    "        min_idx = i\n",
    "        for j in range(i, len(a)):\n",
    "            if a[j] < a[min_idx]:\n",
    "                min_idx = j \n",
    "        if min_idx != i:\n",
    "            a[min_idx], a[i] = a[i], a[min_idx]\n",
    "\n",
    "def insertion_sort(a):\n",
    "    for i in range(1, len(a)):\n",
    "        j = i\n",
    "        while j > 0 and a[j] < a[j - 1]:\n",
    "            a[j], a[j - 1] = a[j - 1], a[j]\n",
    "            j -= 1\n",
    "\n",
    "def shell_sort(a, increment=None):\n",
    "    increment = max(0, increment) if increment is not None else len(a) // 2\n",
    "    for gap in range(increment, 0, -1):\n",
    "        for i in range(gap, len(a), gap):\n",
    "            j = i\n",
    "            while j > 0 and a[j] < a[j - gap]:\n",
    "                a[j], a[j - gap] = a[j - gap], a[j]\n",
    "                j -= gap\n",
    "\n",
    "def merge_sort(a):\n",
    "    if len(a) == 1:\n",
    "        return a\n",
    "    else:\n",
    "        mid = len(a) // 2\n",
    "        return merge(merge_sort(a[:mid]), merge_sort(a[mid:]))\n",
    "\n",
    "def merge(a1, a2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    new_a = []\n",
    "\n",
    "    while p1 < len(a1) and p2 < len(a2):\n",
    "        if a1[p1] <= a2[p2]:\n",
    "            new_a += [a1[p1]]\n",
    "            p1 += 1\n",
    "        else:\n",
    "            new_a += [a2[p2]]\n",
    "            p2 += 1\n",
    "\n",
    "    while p1 < len(a1):\n",
    "        new_a += [a1[p1]]\n",
    "        p1 += 1\n",
    "\n",
    "    while p2 < len(a2):\n",
    "        new_a += [a2[p2]]\n",
    "        p2 += 1\n",
    "\n",
    "    return new_a\n",
    "\n",
    "def quick_sort(a, low=None, high=None):\n",
    "    if low is None:\n",
    "        low = 0 \n",
    "    if high is None:\n",
    "        high = len(a) - 1\n",
    "\n",
    "    if low < high:\n",
    "        separator = partition(a, low, high)\n",
    "        quick_sort(a, low, separator) \n",
    "        quick_sort(a, separator + 1, high)\n",
    "\n",
    "def partition(a, low, high):\n",
    "    pivot = random.randint(low, high)\n",
    "\n",
    "    la = [n for n in a[low:high + 1] if n <= a[pivot]]\n",
    "    ha = [n for n in a[low:high + 1] if n > a[pivot]]\n",
    "    \n",
    "    new_a = la + ha\n",
    "    a[low:high + 1] = new_a[:]\n",
    "\n",
    "    return low + len(la) - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how sorting a list with each of these algorithms works out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc1c445b68446493975f0f4c1120652b32b7ff2d59b9297499b6aaef4c1ff08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
